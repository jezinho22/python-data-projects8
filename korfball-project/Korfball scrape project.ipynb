{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first cell collects fixture numbers which can be used as appendices to web addresses to get all the matches played in a league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "                    \n",
    "#get the match page refs\n",
    "\n",
    "def page_getter(page_address):#take page address and return all the html, includes a pause so that all scripts\n",
    "                              #on page load\n",
    "    driver.get(page_address)\n",
    "    page = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "    #print (\"Opened   \" + page_address)\n",
    "    time.sleep(10 + random.random()) #pause of 15 secs plus random    \n",
    "    soup = BeautifulSoup(page, \"html\")  #or lxml?\n",
    "    return soup\n",
    "\n",
    "def get_rows(soup):#take the html, extract all the rows of matches\n",
    "    #trap bad load error - no rows to get\n",
    "    if not soup.find('b', string = 'Full listing of all matches'):\n",
    "        print (\"Lost page\")\n",
    "        pageload = False\n",
    "        return pageload\n",
    "    #page loaded OK - crack on\n",
    "    rows = soup.find('b', string = 'Full listing of all matches').find_next('tbody').find_all('tr')\n",
    "    return rows\n",
    "\n",
    "\n",
    "def get_fixtures (rows, lstPages):\n",
    "    stop = 0\n",
    "    matchcount = 0\n",
    "    for row in rows[1:]: #first row is header\n",
    "        \n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        #break out for end of completed matches\n",
    "        if cells[3].text == chr(160):  #if match complete, this will be a score; if space/chr(160), then match not completed\n",
    "            stop = 1 #signal that no more completed fixtures #don't need this if we just return out of the func\n",
    "            print (f\"Reached end of completed matches. {matchcount} matches added\")\n",
    "            return lstPages, stop #just get out and return where we are up to\n",
    "        \n",
    "        fixture = row.find('p').text #grab the bit of text with fixture\n",
    "        lstPages.append(fixture.replace(\"Fixture ID: \", \"\")) #reduce to just the ref number - this will become a web address later\n",
    "        matchcount+= 1\n",
    "    print (f\"Reached end of page. {matchcount} matches added\")\n",
    "    return lstPages,stop    #all rows finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictkorfballpages = {'premier': ['https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60175', \n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60175%26page%3d2',\n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60175%26page%3d3'],\n",
    "                   'southeast': ['https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60200', \n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60200%26page%3d2',\n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60200%26page%3d3'],\n",
    "                    'norfolk1': ['https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60191',\n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60191%26page%3d2',\n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60993',\n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60994'],\n",
    "                     'norfolk2':['https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60192',\n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60192%26page%3d2',\n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60995',\n",
    "                                 'https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60996']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>Full listing of all matches</b>\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "soup = page_getter('https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60200%26page%3d3')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached end of completed matches. 3 matches added\n",
      "(['2236236', '2236235', '2236237'], 1)\n"
     ]
    }
   ],
   "source": [
    "rows = get_rows(soup)\n",
    "lstPages = []\n",
    "def get_fixtures (rows, lstPages):\n",
    "    stop = 0\n",
    "    matchcount = 0\n",
    "    for row in rows[1:]: #first row is header\n",
    "\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        #break out for end of completed matches\n",
    "        if cells[3].text == chr(160):  #if match complete, this will be a score; if space/chr(160), then match not completed            \n",
    "            print (f\"Reached end of completed matches. {matchcount} matches added\")\n",
    "            return lstPages #just get out and return where we are up to\n",
    "        \n",
    "        fixture = row.find('p').text #grab the bit of text with fixture\n",
    "        lstPages.append(fixture.replace(\"Fixture ID: \", \"\")) #reduce to just the ref number - this will become a web address later\n",
    "        matchcount+= 1\n",
    "    print (f\"Reached end of page. {matchcount} matches added\")\n",
    "    return lstPages,stop    #all rows finished\n",
    "print (get_fixtures (rows, lstPages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harrow Vultrix Senior 1st', '22', '-', '11', '', 'Cambridge Tigers 2']\n",
      "['KV 2', '18', '-', '17', '', 'Kingfisher 2']\n",
      "['Norwich Knights 2', '15', '-', '15', '', 'Bearsted 1']\n"
     ]
    }
   ],
   "source": [
    "place = soup.find('b', string = 'Full listing of all matches')\n",
    "tbody = place.find_next('tbody')\n",
    "    if x[3] != chr(160):\n",
    "        print ((x)[2:8])\n",
    "        lstdone.append(tr)\n",
    "    lstall.append(tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60192\n",
      "Lost page\n",
      "https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60192\n",
      "Reached end of page. 30 matches added\n",
      "Successful page\n",
      "https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60192%26page%3d2\n",
      "Lost page\n",
      "https://w.fixtureslive.com/staticapi.aspx?a=comp_all_fixtures.ashx%3fdivisionID%3d60192%26page%3d2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-423-2a7557dadcff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#call function and return rows with fixtures in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrows\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#get_rows has said there WERE rows - scripts loaded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mlstPages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_fixtures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstPages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Successful page'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-421-e52b9fd2d1a7>\u001b[0m in \u001b[0;36mget_fixtures\u001b[1;34m(rows, lstPages)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mfixture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;31m#grab the bit of text with fixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mlstPages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fixture ID: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#reduce to just the ref number - this will become a web address later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mmatchcount\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mf\"Reached end of page. {matchcount} matches added\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "#the page list getter\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "lstPages = []\n",
    "\n",
    "for address in dictkorfballpages['norfolk2']: #from page list above\n",
    "    success = 0\n",
    "\n",
    "    while success == 0:\n",
    "        print(address)\n",
    "        soup = page_getter(address) #call function and return soup\n",
    "        rows = get_rows(soup) #call function and return rows with fixtures in\n",
    "        if rows != False: #get_rows has said there WERE rows - scripts loaded               \n",
    "            lstPages = get_fixtures(rows, lstPages)\n",
    "            success = 1\n",
    "            print ('Successful page')\n",
    "            \n",
    "print (lstPages)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print (len(lstPages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 2241244\n",
      "Try 2241244\n",
      "Try 2241245\n",
      "Try 2241245\n",
      "Try 2241246\n",
      "Try 2241246\n",
      "Try 2241247\n",
      "Try 2241248\n",
      "Try 2241248\n",
      "Try 2241252\n",
      "Try 2241252\n",
      "Try 2241253\n",
      "Try 2241253\n",
      "Try 2241249\n",
      "Try 2241249\n",
      "Try 2241250\n",
      "Try 2241250\n",
      "Try 2241251\n",
      "Try 2241251\n",
      "Try 2246458\n",
      "Try 2246458\n",
      "Try 2246457\n",
      "Try 2246457\n",
      "Try 2246456\n",
      "Try 2246454\n",
      "Try 2246454\n",
      "Try 2246460\n",
      "Try 2246460\n",
      "Try 2246461\n",
      "Try 2246461\n",
      "Try 2246455\n",
      "Try 2246455\n",
      "Try 2246462\n",
      "Try 2246462\n",
      "Try 2246463\n",
      "Try 2246463\n",
      "Try 2246464\n",
      "Try 2246464\n",
      "Try 2246465\n",
      "Try 2246465\n",
      "Try 2246466\n",
      "Try 2246466\n",
      "Try 2246466\n",
      "Try 2246467\n",
      "Try 2246467\n",
      "Try 2246468\n",
      "Try 2246995\n",
      "Try 2246995\n",
      "Try 2246470\n",
      "Try 2246470\n",
      "Try 2246471\n",
      "Try 2246471\n",
      "Try 2246471\n",
      "Try 2246472\n",
      "Try 2246472\n",
      "Try 2246473\n",
      "Try 2246473\n",
      "Try 2246474\n",
      "Try 2246474\n",
      "Try 2246475\n",
      "Try 2246475\n",
      "Try 2246476\n",
      "Try 2246476\n",
      "Try 2246477\n",
      "Try 2246477\n",
      "Try 2246478\n",
      "Try 2246478\n",
      "Try 2246479\n",
      "Try 2246479\n",
      "Try 2246480\n",
      "Try 2246480\n",
      "Try 2246485\n",
      "Try 2246485\n",
      "Try 2246484\n",
      "Try 2246481\n",
      "Try 2246481\n",
      "Try 2246481\n",
      "Try 2246482\n",
      "Try 2246483\n",
      "Try 2246483\n",
      "Try 2246488\n",
      "Try 2246459\n",
      "Try 2246459\n",
      "Try 2246486\n",
      "Try 2246486\n",
      "Try 2246487\n",
      "Try 2246487\n",
      "Try 2255341\n",
      "Try 2255341\n",
      "Try 2255342\n",
      "Try 2255342\n",
      "Try 2255343\n",
      "Try 2255343\n",
      "Try 2255344\n",
      "Try 2255345\n",
      "Try 2255345\n",
      "Try 2255346\n",
      "Try 2255346\n",
      "Try 2255349\n",
      "Try 2255349\n",
      "Try 2255351\n",
      "Try 2255351\n",
      "Try 2255352\n",
      "Try 2255350\n",
      "Try 2255350\n",
      "Try 2255361\n",
      "Try 2255361\n",
      "Try 2255361\n",
      "Try 2255362\n",
      "Try 2255362\n",
      "Try 2255362\n",
      "Try 2255362\n",
      "Try 2255364\n",
      "Try 2255364\n",
      "Try 2255363\n",
      "Try 2255363\n",
      "Try 2255365\n",
      "Try 2255365\n",
      "Try 2255366\n",
      "Try 2255366\n",
      "Try 2255367\n",
      "Try 2255367\n",
      "Try 2255368\n",
      "Try 2255368\n",
      "Try 2255369\n",
      "Try 2255369\n",
      "Try 2255371\n",
      "Try 2255371\n",
      "Try 2255370\n",
      "Try 2255370\n",
      "Finished. Got 66 fixtures\n",
      "What do you want to call this dictfcontent dictionary?Norfolk2_dictfcontent\n"
     ]
    }
   ],
   "source": [
    "#get all the match pages\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "dictfcontent = {}\n",
    "pageindex = []\n",
    "\n",
    "for page_append in lstPages:\n",
    "    success = 0\n",
    "    while success == 0:\n",
    "        match_soup = page_getter(f\"https://w.fixtureslive.com/staticapi.aspx?a=statzone_match.ashx%3ffixtureID%3d{page_append}\")\n",
    "        fcontent = match_soup.find('div', {'class':'fcontent'})\n",
    "        print (f\"Try {page_append}\")\n",
    "        #ensure page's dynamic content was there, otherwise go again\n",
    "        if fcontent is not None:\n",
    "            dictfcontent[page_append] = str(fcontent) #make soup into a string so it pickles properly\n",
    "            pageindex.append(page_append)\n",
    "            success = 1\n",
    "\n",
    "print(f\"Finished. Got {len(dictfcontent)} fixtures\")\n",
    "\n",
    "dictfcontent ['index'] = pageindex\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "namefile = input(f'What do you want to call this dictfcontent dictionary?')\n",
    "with open(f'{namefile}.txt', 'wb') as handle:\n",
    "    pickle.dump(dictfcontent, handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells all work from a fixture or match page, to extract all the information. Just provide the info in a soup - so that bit of code is still needed - a page getter (there's one above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the collected list of \"fcontent\" html chunks from match pages to extract info about each match - using a list so you can iterate through in order - collect into dictionaries and combine into one dictionary\n",
    "Add the original list of matches to the dictionary as a reference list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Match_info(soup):\n",
    "    match_info = soup.find('div',{'class': 'flMatchDetails'})\n",
    "    #print (match_info.text)\n",
    "    comp = match_info.find_all('div')[0].text\n",
    "    match_date = match_info.find_all('div')[1].text\n",
    "    return comp, match_date\n",
    "\n",
    "#redundant function - replaced by def Teams\n",
    "#extract match squads\n",
    "#I started with a for loop, and then reduced it to a list comprehension\n",
    "#it is even more compressed than scorers (above)\n",
    "'''def Squads(left_sections, right_sections):\n",
    "    dictSquads = {}\n",
    "    dictSquads['home'] = [tr.text for tr in left_sections[2].find_all('tr')]\n",
    "    dictSquads['away'] = [tr.text for tr in right_sections[2].find_all('tr')]\n",
    "    #remove occasional squad numbers, Reserve, and (captain)\n",
    "    for pat, repl in [(\"\\d+\" , \"\"), (\"Reserve\" , \"\"), (r\"\\([^)]*\\)\" , \"\") ]:\n",
    "        dictSquads ['home'] = [re.sub(pat, repl, squadname) for squadname in dictSquads['home']]\n",
    "        dictSquads ['away'] = [re.sub(pat, repl, squadname) for squadname in dictSquads['away']]\n",
    "    return dictSquads'''\n",
    "#redundant function - replaced by def Goals\n",
    "'''def Scorers(left_sections, right_sections):\n",
    "    #extract scorer tags from section [1]\n",
    "    home_name_tags = left_sections[1].find_all('a')\n",
    "    away_name_tags = right_sections[1].find_all('a')\n",
    "    dctScorers = {}\n",
    "    dctScorers ['home'] = [name.text for name in home_name_tags]\n",
    "    dctScorers ['away'] = [name.text for name in away_name_tags]\n",
    "    #could shorten this and put straight into a dictionary\n",
    "    return dctScorers'''\n",
    "#redundant function - replaced by def Goals\n",
    "'''def Result(left_sections, right_sections):\n",
    "    home_team = left_sections[0].find('h2').text\n",
    "    away_team = right_sections[0].find('h2').text\n",
    "    home_score = left_sections[0].find('span', {'class': 'flHeaderScore'}).text\n",
    "    away_score = right_sections[0].find('span', {'class': 'flHeaderScore'}).text\n",
    "    lstResult = [home_team, away_team, home_score, away_score]\n",
    "    return lstResult'''\n",
    "#redundant function - code now within other functions\n",
    "'''def Left_Right_sections(soup):\n",
    "        #extract home and away sections\n",
    "    left_sections = soup.find_all('div', {'class':'fl_left_half'})\n",
    "    right_sections = soup.find_all('div', {'class': 'fl_right_half'})\n",
    "    return left_sections, right_sections\n",
    "'''\n",
    "\n",
    "def Result (matchsoup):\n",
    "    resultplace = matchsoup.find('h2', string = 'Match details')\n",
    "    if resultplace is None:\n",
    "        return ['','','','']\n",
    "    home = resultplace.find_next('div', {'class':'fl_left_half'})\n",
    "    home_score = home.find_next('span', {'class': 'flHeaderScore'}).text\n",
    "    home_team = home.find_next('a').text\n",
    "    away = resultplace.find_next('div', {'class':'fl_right_half'})\n",
    "    away_score = away.find_next('span', {'class': 'flHeaderScore'}).text\n",
    "    away_team = away.find_next('a').text     \n",
    "    results = [home_team, away_team, home_score, away_score]\n",
    "    return results\n",
    "\n",
    "def Teams (matchsoup):\n",
    "    squadplace = matchsoup.find('h3', {'class' : \"flDivider\"}, string = 'Teams')\n",
    "    if squadplace is None:\n",
    "        return {'home': [], 'away': []}\n",
    "    home = squadplace.find_next('div', {'class':'fl_left_half'})\n",
    "    away = squadplace.find_next('div', {'class':'fl_right_half'})\n",
    "    homesquad = [tr.text for tr in home.find_all('tr')]\n",
    "    awaysquad = [tr.text for tr in away.find_all('tr')]\n",
    "    #remove occasional squad numbers, Reserve, and (captain)\n",
    "    for pat, repl in [(\"\\d+\" , \"\"), (\"Reserve\" , \"\"), (r\"\\([^)]*\\)\" , \"\") ]:\n",
    "        homesquad = [re.sub(pat, repl, squadname) for squadname in homesquad]\n",
    "        awaysquad = [re.sub(pat, repl, squadname) for squadname in awaysquad]\n",
    "    dictsquads = {'home': homesquad, 'away': awaysquad}\n",
    "    return dictsquads\n",
    "\n",
    "def Goals (matchsoup):\n",
    "    goalsplace = matchsoup.find('h3', {'class' : \"flDivider\"}, string = 'Goals')\n",
    "    if goalsplace is None:\n",
    "        return {'home': [], 'away': []}\n",
    "    home = goalsplace.find_next ('div', {'class':'fl_left_half'})\n",
    "    homegoals = Goals_in_brackets ([tr.text for tr in home.find_all('tr')])\n",
    "    \n",
    "    away = goalsplace.find_next('div', {'class':'fl_right_half'})\n",
    "    awaygoals = Goals_in_brackets ([tr.text for tr in away.find_all('tr')])\n",
    "    dictscorers = {'home': homegoals, 'away': awaygoals}\n",
    "    return dictscorers\n",
    "\n",
    "def Goals_in_brackets (goalslist):\n",
    "    newlist = []\n",
    "    for x in goalslist:\n",
    "        if re.search(r'\\((.*?)\\)', x): #to check there are brackets - no need to have \"True\" apparently\n",
    "            goals = re.findall(r'\\((.*?)\\)',x) #to find the contents of brackets\n",
    "            name = re.sub(r'\\([^)]*\\)', '', x) #to find brackets and remove\n",
    "            for goal in range(int(goals[0])):\n",
    "                newlist.append(name)\n",
    "        else:\n",
    "            newlist.append(x) #there weren't any brackets\n",
    "    return newlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "souper = BeautifulSoup(dictfcontent['2255370'],'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td><img alt=\"Marion Catlin\" class=\"fl_profile_pic_small\" src=\"https://www.fixtureslive.com/uploads/uphotos/20151218145121200_profile.jpg\"/></td> \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-363-415e8bffcf1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdictscorers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mGoals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictfcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2255361'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-363-415e8bffcf1d>\u001b[0m in \u001b[0;36mGoals\u001b[1;34m(matchsoup)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'Pen'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'fp'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mhomegoals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[1;32melif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\((.*?)\\)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mgoals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\((.*?)\\)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#to find the contents of brackets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\([^)]*\\)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#to find brackets and remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[0;32m    182\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "def Goals (matchsoup):\n",
    "    homegoals = []\n",
    "    awaygoals = []\n",
    "    goalsplace = matchsoup.find('h3', {'class' : \"flDivider\"}, string = 'Goals')\n",
    "    if goalsplace is None:\n",
    "        return {'home': [], 'away': []}\n",
    "    home = goalsplace.find_next ('div', {'class':'fl_left_half'})\n",
    "    for tr in home.find_all('tr'):\n",
    "        for td in tr.find_all('td'):\n",
    "            print (td, '\\n')\n",
    "            if td.text != 'Pen' and td.text != 'fp' and td.text != '':\n",
    "                homegoals.append(td.text)\n",
    "            elif re.search(r'\\((.*?)\\)', x):\n",
    "                goals = re.findall(r'\\((.*?)\\)',x) #to find the contents of brackets\n",
    "                name = re.sub(r'\\([^)]*\\)', '', x) #to find brackets and remove\n",
    "                for goal in range(int(goals[0])):\n",
    "                    newlist.append(name)\n",
    "\n",
    "    away = goalsplace.find_next('div', {'class':'fl_right_half'})\n",
    "    for tr in away.find_all('tr'):\n",
    "        for td in tr.find_all('td'):\n",
    "            if td.text != 'Pen' and td.text != 'fp' and td.text != '':\n",
    "                awaygoals.append(td.text)\n",
    "    dictscorers = {'home': Goals_in_brackets (homegoals), 'away': Goals_in_brackets (awaygoals)}\n",
    "    return dictscorers\n",
    "\n",
    "print (Goals(BeautifulSoup(dictfcontent['2255361'],'lxml')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2241244', '2241245', '2241246', '2241247', '2241248', '2241252', '2241253', '2241249', '2241250', '2241251', '2246458', '2246457', '2246456', '2246454', '2246460', '2246461', '2246455', '2246462', '2246463', '2246464', '2246465', '2246466', '2246467', '2246468', '2246995', '2246470', '2246471', '2246472', '2246473', '2246474', '2246475', '2246476', '2246477', '2246478', '2246479', '2246480', '2246485', '2246484', '2246481', '2246482', '2246483', '2246488', '2246459', '2246486', '2246487', '2255341', '2255342', '2255343', '2255344', '2255345', '2255346', '2255349', '2255351', '2255352', '2255350', '2255361', '2255362', '2255364', '2255363', '2255365', '2255366', '2255367', '2255368', '2255369', '2255371', '2255370']\n"
     ]
    }
   ],
   "source": [
    "print (dictMatches['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the fcontent file?Norfolk2_dictfcontent\n",
      "Name the dictMatches file - it is for Norfolk Korfball League Norfolk League 2B  Norfolk2_match_facts\n",
      "['Norwich Ice 3', 'Norwich City 5', 'Norwich Knights 6', 'University of East Anglia 4', 'Norwich City 4', 'Norfolk Dragons Dragons 3', 'Norwich Knights 5', 'University of East Anglia 3', 'Colchester Hornets 1', 'Norwich City 6th']\n"
     ]
    }
   ],
   "source": [
    "#2255371, 2255370\n",
    "\n",
    "dictMatches = {}\n",
    "lstrefs = []\n",
    "lstteams = []\n",
    "\n",
    "filename = input ('What is the name of the fcontent file?')\n",
    "with open(f'{filename}.txt', 'rb') as handle:\n",
    "    dictfcontent = pickle.loads(handle.read())\n",
    "\n",
    "#run functions to strip out data\n",
    "for ref in dictfcontent['index']:\n",
    "    \n",
    "    matchsoup = BeautifulSoup(dictfcontent[ref], 'lxml')\n",
    "    \n",
    "    reference = ref\n",
    "\n",
    "    competition, matchday = Match_info(matchsoup)\n",
    "\n",
    "    dictScorers = Goals (matchsoup)\n",
    "\n",
    "    lstResult = Result(matchsoup)\n",
    "\n",
    "    dictSquads = Teams (matchsoup)\n",
    "\n",
    "    lstteams.append(lstResult[0])#make a list of teams\n",
    "    lstteams.append(lstResult[1])\n",
    "\n",
    "    #add data to empty dataframe\n",
    "    dfmatch = pd.DataFrame.from_dict({\"date\": [matchday],\n",
    "             \"result\" : [[lstResult[x] for x in [0,2,1,3]]],\n",
    "             lstResult[0] + '_squad': dictSquads['home'],\n",
    "             lstResult[1] + '_squad': dictSquads['away'],\n",
    "             lstResult[0] + '_scorers': dictScorers['home'],\n",
    "             lstResult[1] + '_scorers': dictScorers['away']}, orient = 'index')\n",
    "    dfmatch2 = dfmatch.T.reset_index()\n",
    "\n",
    "    dictMatches[str(reference)] = dfmatch2\n",
    "    lstrefs.append(reference)\n",
    "    \n",
    "#add a list of match reference numbers\n",
    "dictMatches['index']= lstrefs\n",
    "#add a list of the teams, boiled down to one of each team\n",
    "lstteams = list(set(lstteams))\n",
    "dictMatches['teams']= lstteams\n",
    "\n",
    "filename = input(f'Name the dictMatches file - it is for {competition}  ')\n",
    "with open(f'{filename}.txt', 'wb') as handle:\n",
    "  pickle.dump(dictMatches, handle)\n",
    "\n",
    "\n",
    "\n",
    "print (dictMatches['teams'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University of East Anglia 3', 'Norwich Ice 3', '5', '1']\n",
      "['University of East Anglia 3', '5', 'Norwich Ice 3', '1']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (lstResult)\n",
    "print ([lstResult[x] for x in [0,2,1,3]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>result</th>\n",
       "      <th>Colchester Hornets 1_squad</th>\n",
       "      <th>University of East Anglia 3_squad</th>\n",
       "      <th>Colchester Hornets 1_scorers</th>\n",
       "      <th>University of East Anglia 3_scorers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16:30, Sunday, 13 October, 2019</td>\n",
       "      <td>[Colchester Hornets 1, 17, University of East ...</td>\n",
       "      <td>Tom Chennell</td>\n",
       "      <td>Yolanta Connolly-Muzyczka</td>\n",
       "      <td>Tom Chennell</td>\n",
       "      <td>Dan Seagrove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Hollie Clarke</td>\n",
       "      <td>Megan Ellis</td>\n",
       "      <td>Tom Chennell</td>\n",
       "      <td>Ben Sear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Jack Craven</td>\n",
       "      <td>Freddie Elsasser</td>\n",
       "      <td>Tom Chennell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Katie HallMVP</td>\n",
       "      <td>Mary Emmerson</td>\n",
       "      <td>Tom Chennell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alex Martin</td>\n",
       "      <td>Lydia Kittle</td>\n",
       "      <td>Tom Chennell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Michael Ozua</td>\n",
       "      <td>James Mackay</td>\n",
       "      <td>Jack Craven</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Gemma Tighe</td>\n",
       "      <td>Dan Seagrove</td>\n",
       "      <td>Jack Craven</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ben Sear</td>\n",
       "      <td>Jack Craven</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>George Witty</td>\n",
       "      <td>Jack Craven</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alex Martin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alex Martin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alex Martin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alex Martin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Hollie Clarke</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Hollie Clarke</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Hollie Clarke</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Katie Hall</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                             date  \\\n",
       "0       0  16:30, Sunday, 13 October, 2019   \n",
       "1       1                             None   \n",
       "2       2                             None   \n",
       "3       3                             None   \n",
       "4       4                             None   \n",
       "5       5                             None   \n",
       "6       6                             None   \n",
       "7       7                             None   \n",
       "8       8                             None   \n",
       "9       9                             None   \n",
       "10     10                             None   \n",
       "11     11                             None   \n",
       "12     12                             None   \n",
       "13     13                             None   \n",
       "14     14                             None   \n",
       "15     15                             None   \n",
       "16     16                             None   \n",
       "\n",
       "                                               result  \\\n",
       "0   [Colchester Hornets 1, 17, University of East ...   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                                                None   \n",
       "10                                               None   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "\n",
       "   Colchester Hornets 1_squad University of East Anglia 3_squad  \\\n",
       "0                Tom Chennell         Yolanta Connolly-Muzyczka   \n",
       "1               Hollie Clarke                       Megan Ellis   \n",
       "2                 Jack Craven                  Freddie Elsasser   \n",
       "3               Katie HallMVP                     Mary Emmerson   \n",
       "4                 Alex Martin                      Lydia Kittle   \n",
       "5                Michael Ozua                      James Mackay   \n",
       "6                 Gemma Tighe                      Dan Seagrove   \n",
       "7                        None                          Ben Sear   \n",
       "8                        None                      George Witty   \n",
       "9                        None                              None   \n",
       "10                       None                              None   \n",
       "11                       None                              None   \n",
       "12                       None                              None   \n",
       "13                       None                              None   \n",
       "14                       None                              None   \n",
       "15                       None                              None   \n",
       "16                       None                              None   \n",
       "\n",
       "   Colchester Hornets 1_scorers University of East Anglia 3_scorers  \n",
       "0                  Tom Chennell                        Dan Seagrove  \n",
       "1                  Tom Chennell                            Ben Sear  \n",
       "2                  Tom Chennell                                None  \n",
       "3                  Tom Chennell                                None  \n",
       "4                  Tom Chennell                                None  \n",
       "5                   Jack Craven                                None  \n",
       "6                   Jack Craven                                None  \n",
       "7                   Jack Craven                                None  \n",
       "8                   Jack Craven                                None  \n",
       "9                   Alex Martin                                None  \n",
       "10                  Alex Martin                                None  \n",
       "11                  Alex Martin                                None  \n",
       "12                  Alex Martin                                None  \n",
       "13                Hollie Clarke                                None  \n",
       "14                Hollie Clarke                                None  \n",
       "15                Hollie Clarke                                None  \n",
       "16                   Katie Hall                                None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (dictMatches['2241248'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
